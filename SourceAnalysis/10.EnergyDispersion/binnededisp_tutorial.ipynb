{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binned Likelihood with Energy Dispersion (Python)\n",
    "\n",
    "The following tutorial shows a way of performing binned likelihood with energy dispersion. Technical details can be found [here](https://fermi.gsfc.nasa.gov/ssc/data/analysis/documentation/Pass8_edisp_usage.html). This tutorial assumes that you've gone through the standard [binned likelihood](https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/binned_likelihood_tutorial.html) analysis thread. You can also watch a [video tutorial](https://fermi.gsfc.nasa.gov/ssc/data/analysis/video_tutorials/#binned)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "\n",
    " For this thread we use the same data extracted for the [binned likelihood thread](https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/binned_likelihood_tutorial.html) with the following selections:\n",
    "\n",
    "    Search Center (RA,Dec) = (193.98,-5.82)\n",
    "    Radius = 15 degrees\n",
    "    Start Time (MET) = 239557417 seconds (2008-08-04T15:43:37)\n",
    "    Stop Time (MET) = 302572802 seconds (2010-08-04T00:00:00)\n",
    "    Minimum Energy = 100 MeV\n",
    "    Maximum Energy = 500000 MeV\n",
    "\n",
    "We've provided direct links to the event files as well as the spacecraft data file if you don't want to take the time to use the download server. For more information on how to download LAT data please see the [Extract LAT Data](https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/extract_latdata.html) tutorial.\n",
    "\n",
    " * L181126210218F4F0ED2738_PH00.fits (5.4 MB)\n",
    " * L181126210218F4F0ED2738_PH01.fits (10.8 MB)\n",
    " * L181126210218F4F0ED2738_PH02.fits (6.9 MB)\n",
    " * L181126210218F4F0ED2738_PH03.fits (9.8 MB)\n",
    " * L181126210218F4F0ED2738_PH04.fits (7.8 MB)\n",
    " * L181126210218F4F0ED2738_PH05.fits (6.6 MB)\n",
    " * L181126210218F4F0ED2738_PH06.fits (4.8 MB)\n",
    " * L181126210218F4F0ED2738_SC00.fits (256 MB spacecraft file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/L181126210218F4F0ED2738_PH00.fits\n",
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/L181126210218F4F0ED2738_PH01.fits\n",
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/L181126210218F4F0ED2738_PH02.fits\n",
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/L181126210218F4F0ED2738_PH03.fits\n",
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/L181126210218F4F0ED2738_PH04.fits\n",
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/L181126210218F4F0ED2738_PH05.fits\n",
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/L181126210218F4F0ED2738_PH06.fits\n",
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/L181126210218F4F0ED2738_SC00.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!mv *.fits ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll first need to make a file list with the names of your input event files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./data/*PH*.fits > ./data/binned_events.txt\n",
    "!cat ./data/binned_events.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the following analysis we've assumed that you've named your list of data files binned_events.txt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Event Selections\n",
    "\n",
    "You could follow the unbinned likelihood tutorial to perform your event selections using **gtlike*, **gtmktime**, etc. directly from the command line, and then use pylikelihood later.\n",
    "\n",
    "But we're going to go ahead and use python. The `gt_apps` module provides methods to call these tools from within python. This'll get us used to using python.\n",
    "\n",
    " We first import the gt_apps module to gain access to the tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gt_apps as my_apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can see what objects are part of the gt_apps module by executing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Start by running gtselect (called 'filter' in python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.filter['evclass'] = 128\n",
    "my_apps.filter['evtype'] = 3\n",
    "my_apps.filter['ra'] = 193.98\n",
    "my_apps.filter['dec'] = -5.82\n",
    "my_apps.filter['rad'] = 15\n",
    "my_apps.filter['emin'] = 100\n",
    "my_apps.filter['emax'] = 300000\n",
    "my_apps.filter['zmax'] = 90\n",
    "my_apps.filter['tmin'] = 239557417\n",
    "my_apps.filter['tmax'] = 302572802\n",
    "my_apps.filter['infile'] = '@./data/binned_events.txt'\n",
    "my_apps.filter['outfile'] = './data/3C279_filtered.fits'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is done, we can run gtselect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.filter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, we need to find the GTIs. This is accessed within python via the maketime object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.maketime['scfile'] = './data/L181126210218F4F0ED2738_SC00.fits'\n",
    "my_apps.maketime['filter'] = '(DATA_QUAL>0)&&(LAT_CONFIG==1)'\n",
    "my_apps.maketime['roicut'] = 'no'\n",
    "my_apps.maketime['evfile'] = './data/3C279_filtered.fits'\n",
    "my_apps.maketime['outfile'] = './data/3C279_filtered_gti.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.maketime.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livetime and Counts Cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Livetime Cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can now compute the livetime cube. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.expCube['evfile'] = './data/3C279_filtered_gti.fits'\n",
    "my_apps.expCube['scfile'] = './data/L181126210218F4F0ED2738_SC00.fits'\n",
    "my_apps.expCube['outfile'] = './data/3C279_ltcube.fits'\n",
    "my_apps.expCube['zmax'] = 90\n",
    "my_apps.expCube['dcostheta'] = 0.025\n",
    "my_apps.expCube['binsz'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.expCube.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts Cube\n",
    "\n",
    "The counts cube is the counts from our data file binned in space and energy. All of the steps above use a circular ROI (or a cone, really). Once you switch to binned analysis, you start doing things in squares. Your counts cube can only be as big as the biggest square that can fit in the circular ROI you already selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.evtbin['evfile'] = './data/3C279_filtered_gti.fits'\n",
    "my_apps.evtbin['outfile'] = './data/3C279_ccube.fits'\n",
    "my_apps.evtbin['scfile'] = 'NONE'\n",
    "my_apps.evtbin['algorithm'] = 'CCUBE'\n",
    "my_apps.evtbin['nxpix'] = 100\n",
    "my_apps.evtbin['nypix'] = 100\n",
    "my_apps.evtbin['binsz'] = 0.2\n",
    "my_apps.evtbin['coordsys'] = 'CEL'\n",
    "my_apps.evtbin['xref'] = 193.98\n",
    "my_apps.evtbin['yref'] = -5.82\n",
    "my_apps.evtbin['axisrot'] = 0\n",
    "my_apps.evtbin['proj'] = 'AIT'\n",
    "my_apps.evtbin['ebinalg'] = 'LOG'\n",
    "my_apps.evtbin['emin'] = 100\n",
    "my_apps.evtbin['emax'] = 500000\n",
    "my_apps.evtbin['enumbins'] = 37\n",
    "my_apps.evtbin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure Maps\n",
    "The binned exposure map is an exposure map binned in space and energy. We first need to import the python version of 'gtexpcube2' which doesn't have a gtapp version by default. This is easy to do (you can import any of the command line tools into python this way). Then, you can check out the parameters with the pars function. Here we generate exposure maps for the entire sky. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GtApp import GtApp\n",
    "expCube2= GtApp('gtexpcube2','Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expCube2['infile'] = './data/3C279_ltcube.fits'\n",
    "expCube2['cmap'] = 'none'\n",
    "expCube2['outfile'] = './data/3C279_BinnedExpMap.fits'\n",
    "expCube2['irfs'] = 'P8R3_SOURCE_V3'\n",
    "expCube2['evtype'] = '3'\n",
    "expCube2['nxpix'] = 1800\n",
    "expCube2['nypix'] = 900\n",
    "expCube2['binsz'] = 0.2\n",
    "expCube2['coordsys'] = 'CEL'\n",
    "expCube2['xref'] = 193.98\n",
    "expCube2['yref'] = -5.82\n",
    "expCube2['axisrot'] = 0\n",
    "expCube2['proj'] = 'AIT'\n",
    "expCube2['ebinalg'] = 'LOG'\n",
    "expCube2['emin'] = 100\n",
    "expCube2['emax'] = 500000\n",
    "expCube2['enumbins'] = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expCube2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute source maps\n",
    "\n",
    "The sourcemaps step convolves the LAT response with your source model generating maps for each source in the \n",
    "model for use in the likelihood calculation. We use the same [XML file](https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/3C279_input_model.xml) \n",
    "as in the standard [binned likelihood](https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/binned_likelihood_tutorial.html)\n",
    "analysis. Go ahead and download the XML file to your working directory. You will also need the recommended \n",
    "models for a normal point source analysis [gll_iem_v07.fits](https://fermi.gsfc.nasa.gov/ssc/data/analysis/software/aux/4fgl/gll_iem_v07.fits) and [iso_P8R3_SOURCE_V3_v1.txt](https://fermi.gsfc.nasa.gov/ssc/data/analysis/software/aux/iso_P8R3_SOURCE_V3_v1.txt). These should already been in your $FERMI_DIR/refdata/fermi/galdiffuse directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/BinnedLikelihood/3C279_input_model.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv 3C279_input_model.xml data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.srcMaps['expcube'] = './data/3C279_ltcube.fits'\n",
    "my_apps.srcMaps['cmap'] = './data/3C279_ccube.fits'\n",
    "my_apps.srcMaps['srcmdl'] = './data/3C279_input_model.xml'\n",
    "my_apps.srcMaps['bexpmap'] = './data/3C279_BinnedExpMap.fits'\n",
    "my_apps.srcMaps['outfile'] = './data/3C279_srcmap.fits'\n",
    "my_apps.srcMaps['irfs'] = 'P8R3_SOURCE_V3'\n",
    "my_apps.srcMaps['evtype'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_apps.srcMaps.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Likelihood Analysis\n",
    "\n",
    "First, import the BinnedAnalysis library. Then, create a likelihood object for the dataset. For more details on the pyLikelihood module, check out the [pyLikelihood Usage Notes](https://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/python_usage_notes.html). Initially, we will do an analysis without weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLikelihood\n",
    "from BinnedAnalysis import *\n",
    "\n",
    "obs = BinnedObs(srcMaps='./data/3C279_srcmap.fits',binnedExpMap='./data/3C279_BinnedExpMap.fits', expCube='./data/3C279_ltcube.fits',irfs='CALDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like = BinnedAnalysis(obs,'./data/3C279_input_model.xml',optimizer='NewMinuit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the fit and print out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeobj=pyLike.NewMinuit(like.logLike)\n",
    "like.fit(verbosity=0,covar=True,optObject=likeobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that NewMinuit converged. If you get anything other than '0', then NewMinuit didn't converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likeobj.getRetCode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print TS for 3C 279 (4FGL J1256.1-0547)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like.Ts('4FGL J1256.1-0547')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat the likelihood analysis but turning energy dispersion on this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLikelihood\n",
    "from BinnedAnalysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you have to create a BinnedConfig object and pass that object to BinnedAnalusis. For the appropriate choice of edisp_bins, please read [this](https://fermi.gsfc.nasa.gov/ssc/data/analysis/documentation/Pass8_edisp_usage.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = BinnedConfig(edisp_bins=-2)\n",
    "obs2 = BinnedObs(srcMaps='./data/3C279_srcmap.fits',binnedExpMap='./data/3C279_BinnedExpMap.fits',\n",
    "expCube='./data/3C279_ltcube.fits',irfs='CALDB')\n",
    "like2 = BinnedAnalysis(obs2,'./data/3C279_input_model.xml',optimizer='NewMinuit',config=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the fit and print out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likeobj2=pyLike.NewMinuit(like2.logLike)\n",
    "like2.fit(verbosity=0,covar=True,optObject=likeobj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likeobj2.getRetCode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like2.Ts('4FGL J1256.1-0547')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After verifying that the fit converged, we see that the TS including energy dispersion is a bit lower than what we found neglecting energy dispersion. The effect is most relevant at energies < 300 MeV, but also induces a smaller systematic offset at higher energies. Please refer to a more complete explanation [here](https://fermi.gsfc.nasa.gov/ssc/data/analysis/documentation/Pass8_edisp_usage.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
